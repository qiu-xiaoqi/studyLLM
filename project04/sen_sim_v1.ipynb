{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÊñáÊú¨Áõ∏‰ººÂ∫¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 ÂØºÂåÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 Âä†ËΩΩÊï∞ÊçÆÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"../data/train_pair_1w.json\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Êâæ‰∏ÄÈÉ®Â∞èÊó∂ÂÄôÁöÑÂä®ÁîªÁâá', 'sentence2': 'Ê±Ç‰∏ÄÈÉ®Â∞èÊó∂ÂÄôÁöÑÂä®ÁîªÁâá„ÄÇË∞¢‰∫Ü', 'label': '1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = dataset.train_test_split(test_size=0.2)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37f9aa90d8d4fd39c337aae7ba4b41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ced3d66118401cb9dccfb0478cafd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../hfl/chinese-macbert-base\")\n",
    "\n",
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], max_length=128, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = [float(label) for label in examples[\"label\"]]\n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4 ÂàõÂª∫Ê®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertForSequenceClassification # ÂèØ‰ª•ËøõÂÖ•BertForSequenceClassificationËøô‰∏™Á±ªÊü•Áúãnum_labels=1Êó∂ÂÖ∂Â§ÑÁêÜÊñπÂºèÔºà‰∏ªË¶ÅÂéüÁêÜÊòØÂΩìnum_labels=1Êó∂ÂÖ∂Â∞ÜËøô‰∏™‰ªªÂä°ËßÜ‰∏∫ÂõûÂΩí‰ªªÂä°Ôºâ\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../hfl/chinese-macbert-base\", num_labels=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5 ÂàõÂª∫ËØÑ‰º∞ÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "acc_metric = evaluate.load(\"metric_accuracy.py\")\n",
    "f1_metric = evaluate.load(\"metric_f1.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(eval_predict):\n",
    "    predictions, labels = eval_predict\n",
    "    predictions = [int(p > 0.5) for p in predictions]\n",
    "    labels = [int(l) for l in labels]\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
    "    acc.update(f1)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6 TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\llm\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"v1_result\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    per_device_train_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7 Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Êüí\\AppData\\Local\\Temp\\ipykernel_33980\\1995911572.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=eval_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step8 Ê®°ÂûãËÆ≠ÁªÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669f861a3d6d4659a0d09e57833060e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.094, 'grad_norm': 6.957308292388916, 'learning_rate': 1.9733333333333336e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0689, 'grad_norm': 2.536043643951416, 'learning_rate': 1.9466666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0621, 'grad_norm': 1.3592231273651123, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0587, 'grad_norm': 4.83639669418335, 'learning_rate': 1.8933333333333334e-05, 'epoch': 0.16}\n",
      "{'loss': 0.079, 'grad_norm': 4.822652816772461, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0563, 'grad_norm': 3.1282684803009033, 'learning_rate': 1.8400000000000003e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0481, 'grad_norm': 3.0717780590057373, 'learning_rate': 1.8133333333333335e-05, 'epoch': 0.28}\n",
      "{'loss': 0.044, 'grad_norm': 2.2744767665863037, 'learning_rate': 1.7866666666666666e-05, 'epoch': 0.32}\n",
      "{'loss': 0.046, 'grad_norm': 2.238105058670044, 'learning_rate': 1.76e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0549, 'grad_norm': 2.345521926879883, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0545, 'grad_norm': 3.7558116912841797, 'learning_rate': 1.706666666666667e-05, 'epoch': 0.44}\n",
      "{'loss': 0.057, 'grad_norm': 3.515751838684082, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0429, 'grad_norm': 5.746891975402832, 'learning_rate': 1.6533333333333333e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0636, 'grad_norm': 3.199498414993286, 'learning_rate': 1.6266666666666668e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0732, 'grad_norm': 5.751007556915283, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0413, 'grad_norm': 3.971940755844116, 'learning_rate': 1.5733333333333334e-05, 'epoch': 0.64}\n",
      "{'loss': 0.047, 'grad_norm': 2.209923505783081, 'learning_rate': 1.546666666666667e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0614, 'grad_norm': 3.370523691177368, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0522, 'grad_norm': 2.4971299171447754, 'learning_rate': 1.4933333333333335e-05, 'epoch': 0.76}\n",
      "{'loss': 0.04, 'grad_norm': 2.344741106033325, 'learning_rate': 1.4666666666666666e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0507, 'grad_norm': 2.851548433303833, 'learning_rate': 1.4400000000000001e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0492, 'grad_norm': 6.261049270629883, 'learning_rate': 1.4133333333333334e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0564, 'grad_norm': 5.00537633895874, 'learning_rate': 1.3866666666666669e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0606, 'grad_norm': 2.8468809127807617, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0699, 'grad_norm': 4.264319896697998, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3cea509ee24531b2c90f8bb783e474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0736842006444931, 'eval_accuracy': 0.9065, 'eval_f1': 0.8714776632302406, 'eval_runtime': 6.6633, 'eval_samples_per_second': 300.151, 'eval_steps_per_second': 9.455, 'epoch': 1.0}\n",
      "{'loss': 0.0554, 'grad_norm': 7.634251117706299, 'learning_rate': 1.3066666666666668e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0682, 'grad_norm': 5.4067487716674805, 'learning_rate': 1.2800000000000001e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0689, 'grad_norm': 5.286261081695557, 'learning_rate': 1.2533333333333336e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0679, 'grad_norm': 3.5509519577026367, 'learning_rate': 1.2266666666666667e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0454, 'grad_norm': 1.7824488878250122, 'learning_rate': 1.2e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0489, 'grad_norm': 1.3300397396087646, 'learning_rate': 1.1733333333333335e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0674, 'grad_norm': 10.062271118164062, 'learning_rate': 1.1466666666666668e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0542, 'grad_norm': 2.6538259983062744, 'learning_rate': 1.1200000000000001e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0566, 'grad_norm': 3.2170586585998535, 'learning_rate': 1.0933333333333334e-05, 'epoch': 1.36}\n",
      "{'loss': 0.062, 'grad_norm': 4.365608215332031, 'learning_rate': 1.0666666666666667e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0606, 'grad_norm': 1.1427807807922363, 'learning_rate': 1.04e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0566, 'grad_norm': 1.4675489664077759, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0436, 'grad_norm': 4.178494930267334, 'learning_rate': 9.866666666666668e-06, 'epoch': 1.52}\n",
      "{'loss': 0.0529, 'grad_norm': 3.047433853149414, 'learning_rate': 9.600000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 0.0477, 'grad_norm': 2.9096014499664307, 'learning_rate': 9.333333333333334e-06, 'epoch': 1.6}\n",
      "{'loss': 0.0586, 'grad_norm': 3.708080768585205, 'learning_rate': 9.066666666666667e-06, 'epoch': 1.64}\n",
      "{'loss': 0.0584, 'grad_norm': 4.090631484985352, 'learning_rate': 8.8e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0602, 'grad_norm': 2.257784128189087, 'learning_rate': 8.533333333333335e-06, 'epoch': 1.72}\n",
      "{'loss': 0.0676, 'grad_norm': 2.57478928565979, 'learning_rate': 8.266666666666667e-06, 'epoch': 1.76}\n",
      "{'loss': 0.0722, 'grad_norm': 3.512545585632324, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 0.0535, 'grad_norm': 5.4660563468933105, 'learning_rate': 7.733333333333334e-06, 'epoch': 1.84}\n",
      "{'loss': 0.039, 'grad_norm': 2.003326654434204, 'learning_rate': 7.4666666666666675e-06, 'epoch': 1.88}\n",
      "{'loss': 0.0567, 'grad_norm': 2.3444504737854004, 'learning_rate': 7.2000000000000005e-06, 'epoch': 1.92}\n",
      "{'loss': 0.0477, 'grad_norm': 2.5140795707702637, 'learning_rate': 6.9333333333333344e-06, 'epoch': 1.96}\n",
      "{'loss': 0.0499, 'grad_norm': 2.4603309631347656, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6611503f85a4e9db6e5bac32a60b7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06763548403978348, 'eval_accuracy': 0.917, 'eval_f1': 0.8909329829172141, 'eval_runtime': 6.5248, 'eval_samples_per_second': 306.521, 'eval_steps_per_second': 9.655, 'epoch': 2.0}\n",
      "{'loss': 0.0315, 'grad_norm': 1.7196966409683228, 'learning_rate': 6.4000000000000006e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0429, 'grad_norm': 1.5235246419906616, 'learning_rate': 6.133333333333334e-06, 'epoch': 2.08}\n",
      "{'loss': 0.0509, 'grad_norm': 2.693058490753174, 'learning_rate': 5.8666666666666675e-06, 'epoch': 2.12}\n",
      "{'loss': 0.0409, 'grad_norm': 4.674600601196289, 'learning_rate': 5.600000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 0.0502, 'grad_norm': 2.0740509033203125, 'learning_rate': 5.333333333333334e-06, 'epoch': 2.2}\n",
      "{'loss': 0.0356, 'grad_norm': 2.2640721797943115, 'learning_rate': 5.0666666666666676e-06, 'epoch': 2.24}\n",
      "{'loss': 0.0413, 'grad_norm': 2.2498908042907715, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 0.0386, 'grad_norm': 1.6661852598190308, 'learning_rate': 4.533333333333334e-06, 'epoch': 2.32}\n",
      "{'loss': 0.0386, 'grad_norm': 1.4644936323165894, 'learning_rate': 4.266666666666668e-06, 'epoch': 2.36}\n",
      "{'loss': 0.0442, 'grad_norm': 2.3783812522888184, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 0.0453, 'grad_norm': 1.5828579664230347, 'learning_rate': 3.7333333333333337e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0458, 'grad_norm': 1.8694846630096436, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.48}\n",
      "{'loss': 0.0366, 'grad_norm': 1.9705430269241333, 'learning_rate': 3.2000000000000003e-06, 'epoch': 2.52}\n",
      "{'loss': 0.0385, 'grad_norm': 3.851654529571533, 'learning_rate': 2.9333333333333338e-06, 'epoch': 2.56}\n",
      "{'loss': 0.053, 'grad_norm': 2.6412158012390137, 'learning_rate': 2.666666666666667e-06, 'epoch': 2.6}\n",
      "{'loss': 0.0363, 'grad_norm': 1.4153811931610107, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0315, 'grad_norm': 2.387401580810547, 'learning_rate': 2.133333333333334e-06, 'epoch': 2.68}\n",
      "{'loss': 0.0366, 'grad_norm': 1.5424097776412964, 'learning_rate': 1.8666666666666669e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0462, 'grad_norm': 3.333658456802368, 'learning_rate': 1.6000000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0404, 'grad_norm': 0.7544000744819641, 'learning_rate': 1.3333333333333334e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0471, 'grad_norm': 4.256265640258789, 'learning_rate': 1.066666666666667e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0379, 'grad_norm': 2.3000731468200684, 'learning_rate': 8.000000000000001e-07, 'epoch': 2.88}\n",
      "{'loss': 0.032, 'grad_norm': 1.0153969526290894, 'learning_rate': 5.333333333333335e-07, 'epoch': 2.92}\n",
      "{'loss': 0.0441, 'grad_norm': 1.7715967893600464, 'learning_rate': 2.666666666666667e-07, 'epoch': 2.96}\n",
      "{'loss': 0.0351, 'grad_norm': 2.8311948776245117, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a515fb7be454dee9625690f8c65747d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06780592352151871, 'eval_accuracy': 0.9165, 'eval_f1': 0.8900592495062543, 'eval_runtime': 6.4317, 'eval_samples_per_second': 310.96, 'eval_steps_per_second': 9.795, 'epoch': 3.0}\n",
      "{'train_runtime': 291.1668, 'train_samples_per_second': 82.427, 'train_steps_per_second': 2.576, 'train_loss': 0.051644726713498436, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=0.051644726713498436, metrics={'train_runtime': 291.1668, 'train_samples_per_second': 82.427, 'train_steps_per_second': 2.576, 'total_flos': 1556485250567424.0, 'train_loss': 0.051644726713498436, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step9 Ê®°ÂûãËØÑ‰º∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802e9a00c60144969064cbbea5d681f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.06763548403978348,\n",
       " 'eval_accuracy': 0.917,\n",
       " 'eval_f1': 0.8909329829172141,\n",
       " 'eval_runtime': 6.6259,\n",
       " 'eval_samples_per_second': 301.845,\n",
       " 'eval_steps_per_second': 9.508,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step10 Ê®°ÂûãÈ¢ÑÊµã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {0: \"‰∏çÁõ∏‰ºº\", 1: \"Áõ∏‰ºº\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': '‰∏çÁõ∏‰ºº', 'score': 0.03655894473195076}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipe({\"text\": \"ÊàëÂñúÊ¨¢Âåó‰∫¨\", \"text_pair\":\"Â§©Ê∞îÊÄéÊ†∑\"}, function_to_apply=\"none\")\n",
    "result[\"label\"] = \"Áõ∏‰ºº\" if result[\"score\"] > 0.5 else \"‰∏çÁõ∏‰ºº\"\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
