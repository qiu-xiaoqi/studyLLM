{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, batch_size, hidden_dim, num_heads, dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.h_dim = hidden_dim\n",
    "        self.n_heads = num_heads\n",
    "\n",
    "        assert self.h_dim % self.n_heads == 0\n",
    "        self.bs = batch_size\n",
    "        self.w_q = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w_k = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w_v = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim // num_heads]))\n",
    "    \n",
    "    def forward(self, q, k, v, Mask=None):\n",
    "        self.mask = Mask\n",
    "        \n",
    "        Q = self.w_q(q)\n",
    "        K = self.w_k(k)\n",
    "        V = self.w_v(v)\n",
    "\n",
    "        Q = Q.view(self.bs, -1, self.n_heads, self.h_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        K = K.view(self.bs, -1, self.n_heads, self.h_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        V = V.view(self.bs, -1, self.n_heads, self.h_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        \n",
    "        att_scores = self.attention(Q, K, V, self.mask)\n",
    "        return att_scores\n",
    "    \n",
    "\n",
    "    def attention(self, Q, K, V, Mask):\n",
    "        scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        if Mask is not None:\n",
    "            scores = scores.masked_fill(Mask==0, -1e10)\n",
    "        \n",
    "        sft_scores = self.dropout(torch.softmax(scores, dim=-1))\n",
    "\n",
    "        output = torch.matmul(sft_scores, V)\n",
    "\n",
    "        output = output.permute(0, 2, 1, 3).contiguous()\n",
    "        output = output.view(self.bs, -1, self.h_dim)\n",
    "        \n",
    "        output = self.w_o(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1847,  0.1332,  0.1810,  ...,  0.1395,  0.0891,  0.0164],\n",
       "         [-0.2831,  0.0968,  0.2607,  ...,  0.0749,  0.0551, -0.0144],\n",
       "         [-0.1594,  0.1094,  0.1718,  ...,  0.1591,  0.0712, -0.0204],\n",
       "         ...,\n",
       "         [-0.1714,  0.1697,  0.2321,  ...,  0.1548,  0.1060, -0.0109],\n",
       "         [-0.2557,  0.1208,  0.2601,  ...,  0.1334,  0.0721, -0.0028],\n",
       "         [-0.2001,  0.1494,  0.2060,  ...,  0.1904,  0.0636, -0.0242]],\n",
       "\n",
       "        [[-0.2306,  0.1464,  0.2053,  ...,  0.1728,  0.0129, -0.0715],\n",
       "         [-0.1311,  0.1801,  0.1181,  ...,  0.1231, -0.0084, -0.0314],\n",
       "         [-0.1773,  0.2176,  0.1569,  ...,  0.1959, -0.0013, -0.0103],\n",
       "         ...,\n",
       "         [-0.1553,  0.2128,  0.1303,  ...,  0.2243, -0.0195, -0.0230],\n",
       "         [-0.1812,  0.1897,  0.1222,  ...,  0.0616, -0.0064, -0.0487],\n",
       "         [-0.2439,  0.1516,  0.1738,  ...,  0.1110, -0.0098, -0.0506]],\n",
       "\n",
       "        [[-0.2014,  0.1517,  0.1643,  ...,  0.1603,  0.0605, -0.0436],\n",
       "         [-0.2008,  0.0615,  0.2367,  ...,  0.1139,  0.0690, -0.0762],\n",
       "         [-0.2574,  0.1211,  0.2352,  ...,  0.1856,  0.0473, -0.0222],\n",
       "         ...,\n",
       "         [-0.1754,  0.1609,  0.1565,  ...,  0.1797,  0.0630, -0.0817],\n",
       "         [-0.2382,  0.1255,  0.1980,  ...,  0.1426,  0.0535, -0.0280],\n",
       "         [-0.2539,  0.0945,  0.1873,  ...,  0.1809,  0.0553, -0.0642]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2638,  0.1537,  0.2608,  ...,  0.1006,  0.0048,  0.0700],\n",
       "         [-0.2878,  0.0585,  0.2189,  ...,  0.0768, -0.0006,  0.0499],\n",
       "         [-0.2796,  0.0712,  0.1741,  ...,  0.1730, -0.0120,  0.0512],\n",
       "         ...,\n",
       "         [-0.2529,  0.1322,  0.1827,  ...,  0.1180,  0.0012,  0.0333],\n",
       "         [-0.1984,  0.1941,  0.1513,  ...,  0.1927, -0.0078,  0.0530],\n",
       "         [-0.2670,  0.0951,  0.2386,  ...,  0.1447,  0.0052,  0.0547]],\n",
       "\n",
       "        [[-0.2446,  0.2498,  0.1877,  ...,  0.0053, -0.0342, -0.0048],\n",
       "         [-0.2496,  0.2344,  0.1686,  ...,  0.0856, -0.0218,  0.0543],\n",
       "         [-0.1598,  0.2315,  0.1293,  ...,  0.0639, -0.0041,  0.0056],\n",
       "         ...,\n",
       "         [-0.1778,  0.2293,  0.1056,  ...,  0.1231, -0.0287, -0.0134],\n",
       "         [-0.2438,  0.1488,  0.1754,  ...,  0.1126, -0.0604, -0.0160],\n",
       "         [-0.2077,  0.2017,  0.1588,  ...,  0.1094, -0.0123,  0.0344]],\n",
       "\n",
       "        [[-0.2068,  0.0692,  0.1486,  ...,  0.2309, -0.0475, -0.0188],\n",
       "         [-0.2234,  0.0638,  0.2162,  ...,  0.1797,  0.0115, -0.0614],\n",
       "         [-0.1811,  0.1320,  0.2110,  ...,  0.1956,  0.0057, -0.0563],\n",
       "         ...,\n",
       "         [-0.2187,  0.1037,  0.1645,  ...,  0.1814, -0.0023, -0.0699],\n",
       "         [-0.2028,  0.1301,  0.1255,  ...,  0.1447,  0.0123, -0.0425],\n",
       "         [-0.2027,  0.1267,  0.1788,  ...,  0.1463, -0.0169, -0.0864]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs, h_dim, n_heads\n",
    "bs = 32\n",
    "q_len = 12\n",
    "k_len, v_len = 10,10\n",
    "h_dim = 512\n",
    "n_heads = 8\n",
    "q = torch.rand(bs, q_len, h_dim)\n",
    "k = torch.rand(bs, k_len, h_dim)\n",
    "v = torch.rand(bs, v_len, h_dim)\n",
    "\n",
    "mha2 = MultiHeadAttention(bs, h_dim, n_heads, 0.2)\n",
    "att2 = mha2(q,k,v)\n",
    "att2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder的组成：\\\n",
    "    - input: PE+WE后的向量 \\\n",
    "    - MHA \\\n",
    "    - Add & LN \\\n",
    "    - FFNN \\\n",
    "    - Add & LN \\\n",
    "    - output：z，K，V向量，z用于下一层Encoder \\\n",
    "Decoder的组成: \\\n",
    "    - input:第一个词是BOS\\\n",
    "    - MHA\\\n",
    "    - Add & LN\\\n",
    "    - Mask MHA\\\n",
    "    - Add & LN\\\n",
    "    - FFNN\\\n",
    "    - Add & LN\\\n",
    "    - softmax\\\n",
    "    - output：作为下一个词的input\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layer = EncoderLayer()\n",
    "        self.norm = LayerNorm()\n",
    "\n",
    "    def forward(self):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformer(nn.Module):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
