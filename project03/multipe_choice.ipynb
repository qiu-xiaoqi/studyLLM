{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于Transformer的多项选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 1625\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 11869\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 3816\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3 = DatasetDict.load_from_disk(\"../data/c3\")\n",
    "c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'context': [['男：你今天晚上有时间吗?我们一起去看电影吧?', '女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……'],\n",
       "  ['男：足球比赛是明天上午八点开始吧?', '女：因为天气不好，比赛改到后天下午三点了。'],\n",
       "  ['女：今天下午的讨论会开得怎么样?', '男：我觉得发言的人太少了。'],\n",
       "  ['男：我记得你以前很爱吃巧克力，最近怎么不吃了，是在减肥吗?', '女：是啊，我希望自己能瘦一点儿。'],\n",
       "  ['女：过几天刘明就要从英国回来了。我还真有点儿想他了，记得那年他是刚过完中秋节走的。',\n",
       "   '男：可不是嘛!自从我去日本留学，就再也没见过他，算一算都五年了。',\n",
       "   '女：从2000年我们在学校第一次见面到现在已经快十年了。我还真想看看刘明变成什么样了!',\n",
       "   '男：你还别说，刘明肯定跟英国绅士一样，也许还能带回来一个英国女朋友呢。'],\n",
       "  ['男：好久不见了，最近忙什么呢?',\n",
       "   '女：最近我们单位要搞一个现代艺术展览，正忙着准备呢。',\n",
       "   '男：你们不是出版公司吗?为什么搞艺术展览?',\n",
       "   '女：对啊，这次展览是我们出版的一套艺术丛书的重要宣传活动。'],\n",
       "  ['男：会议结束后，你记得把空调和灯都关了。', '女：好的，我知道了，明天见。'],\n",
       "  ['男：你出国读书的事定了吗?', '女：思前想后，还拿不定主意呢。'],\n",
       "  ['男：这件衣服我要了，在哪儿交钱?', '女：前边右拐就有一个收银台，可以交现金，也可以刷卡。'],\n",
       "  ['男：小李啊，你是我见过的最爱干净的学生。',\n",
       "   '女：谢谢教授夸奖。不过，您是怎么看出来的?',\n",
       "   '男：不管我叫你做什么，你总是推得干干净净。',\n",
       "   '女：教授，我……']],\n",
       " 'question': ['女的最喜欢哪种电影?',\n",
       "  '根据对话，可以知道什么?',\n",
       "  '关于这次讨论会，我们可以知道什么?',\n",
       "  '女的为什么不吃巧克力了?',\n",
       "  '现在大概是哪一年?',\n",
       "  '女的的公司为什么要做现代艺术展览?',\n",
       "  '他们最可能是什么关系?',\n",
       "  '女的是什么意思?',\n",
       "  '他们最可能在什么地方?',\n",
       "  '教授认为小李怎么样?'],\n",
       " 'choice': [['恐怖片', '爱情片', '喜剧片', '科幻片'],\n",
       "  ['今天天气不好', '比赛时间变了', '校长忘了时间'],\n",
       "  ['会是昨天开的', '男的没有参加', '讨论得不热烈', '参加的人很少'],\n",
       "  ['刷牙了', '要减肥', '口渴了', '吃饱了'],\n",
       "  ['2005年', '2010年', '2008年', '2009年'],\n",
       "  ['传播文化', '宣传新书', '推广现代艺术', '体现企业文化'],\n",
       "  ['同事', '司机和客人', '医生和病人'],\n",
       "  ['不想出国', '出国太难', '还在犹豫', '不想决定'],\n",
       "  ['医院', '迪厅', '商场', '饭馆'],\n",
       "  ['卫生习惯非常好', '做事的能力不够', '找借口拒绝做事', '记不住该做的事']],\n",
       " 'answer': ['喜剧片',\n",
       "  '比赛时间变了',\n",
       "  '讨论得不热烈',\n",
       "  '要减肥',\n",
       "  '2010年',\n",
       "  '宣传新书',\n",
       "  '同事',\n",
       "  '还在犹豫',\n",
       "  '商场',\n",
       "  '找借口拒绝做事']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': [0, 1, 2, 3, 4, 4, 4, 4, 4, 5],\n",
       " 'context': [['男：听说你们公司要派你去南方工作?', '女：是呀，虽说那边环境好，待遇也不错，可我还是觉得在家里最好。'],\n",
       "  ['女：张总，银行来电话说我们的贷款申请批下来了。',\n",
       "   '男：太好了，贷款一到位我们就更新设备。',\n",
       "   '女：这样每个月的出货量大概能提高百分之三十。',\n",
       "   '男：对，让市场部抓紧时间多联系些新客户。'],\n",
       "  ['男：请问现在能预订晚上的座位吗?',\n",
       "   '女：可以。您贵姓?几位?',\n",
       "   '男：我姓张，两位。大概六点半到，麻烦给我留个靠窗的位置。',\n",
       "   '女：好，我们最晚给您保留到七点，请尽早过来。'],\n",
       "  ['女：喂，你到哪儿了?我们都在等你呢!', '男：马上，我马上就到!我已经下了公交车了，正往你们那儿赶呢!'],\n",
       "  ['女：大家好，欢迎你们来北京!我是你们的导游——王丽娜。大家可以叫我小王或者王导。',\n",
       "   '男：王导，北京有这么多的名胜古迹，还有这么多的新建筑，真有点儿让人看不过来了。你先为我们介绍一下我们现在所在的“鸟巢”吧。',\n",
       "   '女：好!你们知道2008年奥运会开幕式和闭幕式是在哪里举行的吗?',\n",
       "   '男：好像在这里吧。',\n",
       "   '女：对。“鸟巢”位于北京奥林匹克公园内。奥林匹克公园由鸟巢、水立方、国家体育馆等赛场以及新闻中心和运动员村组成，“鸟巢”是奥运会的主会馆，是北京奥运的核心。2008年奥运会期间，“鸟巢”承担了开幕式、闭幕式、田径比赛、男子足球决赛等赛事活动。',\n",
       "   '男：这个“鸟巢”可真大啊!',\n",
       "   '女：“鸟巢”能容纳观众10万人，其中临时坐席两万座。“鸟巢”可承担特殊重大体育比赛、各类常规赛事以及非竞赛项目，现在已经成为北京市提供市民广泛参与体育活动及享受体育娱乐的大型专业场所，成为全国具有标志性的体育娱乐建筑。',\n",
       "   '男：“鸟巢”是由谁来设计的?',\n",
       "   '女：“鸟巢”2001年由普利茨克奖获得者赫尔佐格和德梅隆，还有中国建筑师李兴刚等合作完成设计。其形态如同孕育生命的“巢”，它更像一个摇篮，寄托着人类对未来的希望。设计者们对这个国家体育场没有作任何多余的处理，只是坦率地把结构暴露在外，因而自然形成了建筑的外观。',\n",
       "   '男：“鸟巢”的设计理念是什么?',\n",
       "   '女：场馆设计如同一个巨大的容器，高低起伏变化的外观缓和了建筑的体量感，与周围建筑环境相协调，并赋予了戏剧性和具有震撼力的形体。“鸟巢”形象完美纯净，外观即为建筑的结构，立面与结构达到了完美的统一。结构的组件相互支撑，形成了网络状的构架，就像树枝编织的鸟巢。体育场的空间效果具有前所未有的独创性，又简洁而典雅，为2008年奥运会树立了一座独特的历史性的标志性建筑。',\n",
       "   '男：“鸟巢”的设计有什么特别的地方?',\n",
       "   '女：“鸟巢”是为人设计的，设计中充分体现了人文关怀。无论观众坐在哪个位置，和赛场中心点之间的视线距离都在140米左右。“鸟巢”采用的吸声材料和电声扩音系统，使“巢”内的语音清晰度指标指数达到0.6——这个数字保证了坐在任何位置的观众都能清晰地收听到广播。“鸟巢”的相关设计师们还运用流体力学设计，让所有观众都能享有同样的自然光和自然通风。“鸟巢”的观众席里，还为残障人士设置了200多个轮椅坐席。这些轮椅坐席比普通坐席稍高，保证残障人士和普通观众有一样的视野。赛时，场内还将提供助听器并设置无线广播系统，为有听力和视力障碍的人提供个性化的服务。另外，“鸟巢”采用太阳能光伏发电系统，设计中渗透着很多环保理念和科技手段。'],\n",
       "  ['女：大家好，欢迎你们来北京!我是你们的导游——王丽娜。大家可以叫我小王或者王导。',\n",
       "   '男：王导，北京有这么多的名胜古迹，还有这么多的新建筑，真有点儿让人看不过来了。你先为我们介绍一下我们现在所在的“鸟巢”吧。',\n",
       "   '女：好!你们知道2008年奥运会开幕式和闭幕式是在哪里举行的吗?',\n",
       "   '男：好像在这里吧。',\n",
       "   '女：对。“鸟巢”位于北京奥林匹克公园内。奥林匹克公园由鸟巢、水立方、国家体育馆等赛场以及新闻中心和运动员村组成，“鸟巢”是奥运会的主会馆，是北京奥运的核心。2008年奥运会期间，“鸟巢”承担了开幕式、闭幕式、田径比赛、男子足球决赛等赛事活动。',\n",
       "   '男：这个“鸟巢”可真大啊!',\n",
       "   '女：“鸟巢”能容纳观众10万人，其中临时坐席两万座。“鸟巢”可承担特殊重大体育比赛、各类常规赛事以及非竞赛项目，现在已经成为北京市提供市民广泛参与体育活动及享受体育娱乐的大型专业场所，成为全国具有标志性的体育娱乐建筑。',\n",
       "   '男：“鸟巢”是由谁来设计的?',\n",
       "   '女：“鸟巢”2001年由普利茨克奖获得者赫尔佐格和德梅隆，还有中国建筑师李兴刚等合作完成设计。其形态如同孕育生命的“巢”，它更像一个摇篮，寄托着人类对未来的希望。设计者们对这个国家体育场没有作任何多余的处理，只是坦率地把结构暴露在外，因而自然形成了建筑的外观。',\n",
       "   '男：“鸟巢”的设计理念是什么?',\n",
       "   '女：场馆设计如同一个巨大的容器，高低起伏变化的外观缓和了建筑的体量感，与周围建筑环境相协调，并赋予了戏剧性和具有震撼力的形体。“鸟巢”形象完美纯净，外观即为建筑的结构，立面与结构达到了完美的统一。结构的组件相互支撑，形成了网络状的构架，就像树枝编织的鸟巢。体育场的空间效果具有前所未有的独创性，又简洁而典雅，为2008年奥运会树立了一座独特的历史性的标志性建筑。',\n",
       "   '男：“鸟巢”的设计有什么特别的地方?',\n",
       "   '女：“鸟巢”是为人设计的，设计中充分体现了人文关怀。无论观众坐在哪个位置，和赛场中心点之间的视线距离都在140米左右。“鸟巢”采用的吸声材料和电声扩音系统，使“巢”内的语音清晰度指标指数达到0.6——这个数字保证了坐在任何位置的观众都能清晰地收听到广播。“鸟巢”的相关设计师们还运用流体力学设计，让所有观众都能享有同样的自然光和自然通风。“鸟巢”的观众席里，还为残障人士设置了200多个轮椅坐席。这些轮椅坐席比普通坐席稍高，保证残障人士和普通观众有一样的视野。赛时，场内还将提供助听器并设置无线广播系统，为有听力和视力障碍的人提供个性化的服务。另外，“鸟巢”采用太阳能光伏发电系统，设计中渗透着很多环保理念和科技手段。'],\n",
       "  ['女：大家好，欢迎你们来北京!我是你们的导游——王丽娜。大家可以叫我小王或者王导。',\n",
       "   '男：王导，北京有这么多的名胜古迹，还有这么多的新建筑，真有点儿让人看不过来了。你先为我们介绍一下我们现在所在的“鸟巢”吧。',\n",
       "   '女：好!你们知道2008年奥运会开幕式和闭幕式是在哪里举行的吗?',\n",
       "   '男：好像在这里吧。',\n",
       "   '女：对。“鸟巢”位于北京奥林匹克公园内。奥林匹克公园由鸟巢、水立方、国家体育馆等赛场以及新闻中心和运动员村组成，“鸟巢”是奥运会的主会馆，是北京奥运的核心。2008年奥运会期间，“鸟巢”承担了开幕式、闭幕式、田径比赛、男子足球决赛等赛事活动。',\n",
       "   '男：这个“鸟巢”可真大啊!',\n",
       "   '女：“鸟巢”能容纳观众10万人，其中临时坐席两万座。“鸟巢”可承担特殊重大体育比赛、各类常规赛事以及非竞赛项目，现在已经成为北京市提供市民广泛参与体育活动及享受体育娱乐的大型专业场所，成为全国具有标志性的体育娱乐建筑。',\n",
       "   '男：“鸟巢”是由谁来设计的?',\n",
       "   '女：“鸟巢”2001年由普利茨克奖获得者赫尔佐格和德梅隆，还有中国建筑师李兴刚等合作完成设计。其形态如同孕育生命的“巢”，它更像一个摇篮，寄托着人类对未来的希望。设计者们对这个国家体育场没有作任何多余的处理，只是坦率地把结构暴露在外，因而自然形成了建筑的外观。',\n",
       "   '男：“鸟巢”的设计理念是什么?',\n",
       "   '女：场馆设计如同一个巨大的容器，高低起伏变化的外观缓和了建筑的体量感，与周围建筑环境相协调，并赋予了戏剧性和具有震撼力的形体。“鸟巢”形象完美纯净，外观即为建筑的结构，立面与结构达到了完美的统一。结构的组件相互支撑，形成了网络状的构架，就像树枝编织的鸟巢。体育场的空间效果具有前所未有的独创性，又简洁而典雅，为2008年奥运会树立了一座独特的历史性的标志性建筑。',\n",
       "   '男：“鸟巢”的设计有什么特别的地方?',\n",
       "   '女：“鸟巢”是为人设计的，设计中充分体现了人文关怀。无论观众坐在哪个位置，和赛场中心点之间的视线距离都在140米左右。“鸟巢”采用的吸声材料和电声扩音系统，使“巢”内的语音清晰度指标指数达到0.6——这个数字保证了坐在任何位置的观众都能清晰地收听到广播。“鸟巢”的相关设计师们还运用流体力学设计，让所有观众都能享有同样的自然光和自然通风。“鸟巢”的观众席里，还为残障人士设置了200多个轮椅坐席。这些轮椅坐席比普通坐席稍高，保证残障人士和普通观众有一样的视野。赛时，场内还将提供助听器并设置无线广播系统，为有听力和视力障碍的人提供个性化的服务。另外，“鸟巢”采用太阳能光伏发电系统，设计中渗透着很多环保理念和科技手段。'],\n",
       "  ['女：大家好，欢迎你们来北京!我是你们的导游——王丽娜。大家可以叫我小王或者王导。',\n",
       "   '男：王导，北京有这么多的名胜古迹，还有这么多的新建筑，真有点儿让人看不过来了。你先为我们介绍一下我们现在所在的“鸟巢”吧。',\n",
       "   '女：好!你们知道2008年奥运会开幕式和闭幕式是在哪里举行的吗?',\n",
       "   '男：好像在这里吧。',\n",
       "   '女：对。“鸟巢”位于北京奥林匹克公园内。奥林匹克公园由鸟巢、水立方、国家体育馆等赛场以及新闻中心和运动员村组成，“鸟巢”是奥运会的主会馆，是北京奥运的核心。2008年奥运会期间，“鸟巢”承担了开幕式、闭幕式、田径比赛、男子足球决赛等赛事活动。',\n",
       "   '男：这个“鸟巢”可真大啊!',\n",
       "   '女：“鸟巢”能容纳观众10万人，其中临时坐席两万座。“鸟巢”可承担特殊重大体育比赛、各类常规赛事以及非竞赛项目，现在已经成为北京市提供市民广泛参与体育活动及享受体育娱乐的大型专业场所，成为全国具有标志性的体育娱乐建筑。',\n",
       "   '男：“鸟巢”是由谁来设计的?',\n",
       "   '女：“鸟巢”2001年由普利茨克奖获得者赫尔佐格和德梅隆，还有中国建筑师李兴刚等合作完成设计。其形态如同孕育生命的“巢”，它更像一个摇篮，寄托着人类对未来的希望。设计者们对这个国家体育场没有作任何多余的处理，只是坦率地把结构暴露在外，因而自然形成了建筑的外观。',\n",
       "   '男：“鸟巢”的设计理念是什么?',\n",
       "   '女：场馆设计如同一个巨大的容器，高低起伏变化的外观缓和了建筑的体量感，与周围建筑环境相协调，并赋予了戏剧性和具有震撼力的形体。“鸟巢”形象完美纯净，外观即为建筑的结构，立面与结构达到了完美的统一。结构的组件相互支撑，形成了网络状的构架，就像树枝编织的鸟巢。体育场的空间效果具有前所未有的独创性，又简洁而典雅，为2008年奥运会树立了一座独特的历史性的标志性建筑。',\n",
       "   '男：“鸟巢”的设计有什么特别的地方?',\n",
       "   '女：“鸟巢”是为人设计的，设计中充分体现了人文关怀。无论观众坐在哪个位置，和赛场中心点之间的视线距离都在140米左右。“鸟巢”采用的吸声材料和电声扩音系统，使“巢”内的语音清晰度指标指数达到0.6——这个数字保证了坐在任何位置的观众都能清晰地收听到广播。“鸟巢”的相关设计师们还运用流体力学设计，让所有观众都能享有同样的自然光和自然通风。“鸟巢”的观众席里，还为残障人士设置了200多个轮椅坐席。这些轮椅坐席比普通坐席稍高，保证残障人士和普通观众有一样的视野。赛时，场内还将提供助听器并设置无线广播系统，为有听力和视力障碍的人提供个性化的服务。另外，“鸟巢”采用太阳能光伏发电系统，设计中渗透着很多环保理念和科技手段。'],\n",
       "  ['女：大家好，欢迎你们来北京!我是你们的导游——王丽娜。大家可以叫我小王或者王导。',\n",
       "   '男：王导，北京有这么多的名胜古迹，还有这么多的新建筑，真有点儿让人看不过来了。你先为我们介绍一下我们现在所在的“鸟巢”吧。',\n",
       "   '女：好!你们知道2008年奥运会开幕式和闭幕式是在哪里举行的吗?',\n",
       "   '男：好像在这里吧。',\n",
       "   '女：对。“鸟巢”位于北京奥林匹克公园内。奥林匹克公园由鸟巢、水立方、国家体育馆等赛场以及新闻中心和运动员村组成，“鸟巢”是奥运会的主会馆，是北京奥运的核心。2008年奥运会期间，“鸟巢”承担了开幕式、闭幕式、田径比赛、男子足球决赛等赛事活动。',\n",
       "   '男：这个“鸟巢”可真大啊!',\n",
       "   '女：“鸟巢”能容纳观众10万人，其中临时坐席两万座。“鸟巢”可承担特殊重大体育比赛、各类常规赛事以及非竞赛项目，现在已经成为北京市提供市民广泛参与体育活动及享受体育娱乐的大型专业场所，成为全国具有标志性的体育娱乐建筑。',\n",
       "   '男：“鸟巢”是由谁来设计的?',\n",
       "   '女：“鸟巢”2001年由普利茨克奖获得者赫尔佐格和德梅隆，还有中国建筑师李兴刚等合作完成设计。其形态如同孕育生命的“巢”，它更像一个摇篮，寄托着人类对未来的希望。设计者们对这个国家体育场没有作任何多余的处理，只是坦率地把结构暴露在外，因而自然形成了建筑的外观。',\n",
       "   '男：“鸟巢”的设计理念是什么?',\n",
       "   '女：场馆设计如同一个巨大的容器，高低起伏变化的外观缓和了建筑的体量感，与周围建筑环境相协调，并赋予了戏剧性和具有震撼力的形体。“鸟巢”形象完美纯净，外观即为建筑的结构，立面与结构达到了完美的统一。结构的组件相互支撑，形成了网络状的构架，就像树枝编织的鸟巢。体育场的空间效果具有前所未有的独创性，又简洁而典雅，为2008年奥运会树立了一座独特的历史性的标志性建筑。',\n",
       "   '男：“鸟巢”的设计有什么特别的地方?',\n",
       "   '女：“鸟巢”是为人设计的，设计中充分体现了人文关怀。无论观众坐在哪个位置，和赛场中心点之间的视线距离都在140米左右。“鸟巢”采用的吸声材料和电声扩音系统，使“巢”内的语音清晰度指标指数达到0.6——这个数字保证了坐在任何位置的观众都能清晰地收听到广播。“鸟巢”的相关设计师们还运用流体力学设计，让所有观众都能享有同样的自然光和自然通风。“鸟巢”的观众席里，还为残障人士设置了200多个轮椅坐席。这些轮椅坐席比普通坐席稍高，保证残障人士和普通观众有一样的视野。赛时，场内还将提供助听器并设置无线广播系统，为有听力和视力障碍的人提供个性化的服务。另外，“鸟巢”采用太阳能光伏发电系统，设计中渗透着很多环保理念和科技手段。'],\n",
       "  ['男：根据这份材料整理出一份报告，下班前交给我。', '女：下班前吗?可是我还有两份文件要整理呢。']],\n",
       " 'question': ['他们在谈论什么?',\n",
       "  '他们想用那批贷款做什么?',\n",
       "  '男的在做什么?',\n",
       "  '从这段对话中，我们可以知道什么?',\n",
       "  '“鸟巢”是什么场所?',\n",
       "  '2008年北京奥运会期间，“鸟巢”承担了哪些赛事活动?',\n",
       "  '“鸟巢”是由谁来设计的?',\n",
       "  '为什么取名叫“鸟巢”?',\n",
       "  '下面哪一项不是“鸟巢”的设计特点?',\n",
       "  '女的是什么意思?'],\n",
       " 'choice': [['旅行', '坏境', '工作', '家庭'],\n",
       "  ['建分厂', '买新设备', '购买原料', '为职工上保险'],\n",
       "  ['看急诊', '开发票', '组织聚会', '预订座位'],\n",
       "  ['女的很生气', '男的在车上', '男的就要到了', '女的挂了电话'],\n",
       "  ['名胜古迹', '有名的咖啡馆', '奥运会主会馆', '奥运会足球馆'],\n",
       "  ['游泳比赛', '射击比赛', '女子足球比赛', '男子足球决赛'],\n",
       "  ['建筑设计院', '外国建筑设计师', '中国建筑设计师', '中外建筑师合作'],\n",
       "  ['里面像鸟巢', '外观像鸟巢', '附近鸟巢很多', '里面住着很多鸟'],\n",
       "  ['观众能清晰地收听赛场广播', '采用太阳能光伏发电系统', '每个观众与赛场中心点等距离', '残障人士坐席比普通坐席稍低'],\n",
       "  ['工作任务多', '今晚要加班', '她想先整理两份文件', '没明白男的的意思']],\n",
       " 'answer': ['工作',\n",
       "  '买新设备',\n",
       "  '预订座位',\n",
       "  '男的就要到了',\n",
       "  '奥运会主会馆',\n",
       "  '男子足球决赛',\n",
       "  '中外建筑师合作',\n",
       "  '外观像鸟巢',\n",
       "  '残障人士坐席比普通坐席稍低',\n",
       "  '工作任务多']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3[\"validation\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'context': [['老师把一个大玻璃瓶子带到学校，瓶子里装着满满的石头、玻璃碎片和沙子。之后，老师请学生把瓶子里的东西都倒出来，然后再装进去，先从沙子开始。每个学生都试了试，最后都发现没有足够的空间装所有的石头。老师指导学生重新装这个瓶子。这次，先从石头开始，最后再装沙子。石头装进去后，沙子就沉积在石头的周围，最后，所有东西都装进瓶子里了。老师说：“如果我们先从小的东西开始，把小东西装进去之后，大的石头就放不进去了。生活也是如此，如果你的生活先被不重要的事挤满了，那你就无法再装进更大、更重要的事了。”'],\n",
       "  ['老师把一个大玻璃瓶子带到学校，瓶子里装着满满的石头、玻璃碎片和沙子。之后，老师请学生把瓶子里的东西都倒出来，然后再装进去，先从沙子开始。每个学生都试了试，最后都发现没有足够的空间装所有的石头。老师指导学生重新装这个瓶子。这次，先从石头开始，最后再装沙子。石头装进去后，沙子就沉积在石头的周围，最后，所有东西都装进瓶子里了。老师说：“如果我们先从小的东西开始，把小东西装进去之后，大的石头就放不进去了。生活也是如此，如果你的生活先被不重要的事挤满了，那你就无法再装进更大、更重要的事了。”'],\n",
       "  ['老师把一个大玻璃瓶子带到学校，瓶子里装着满满的石头、玻璃碎片和沙子。之后，老师请学生把瓶子里的东西都倒出来，然后再装进去，先从沙子开始。每个学生都试了试，最后都发现没有足够的空间装所有的石头。老师指导学生重新装这个瓶子。这次，先从石头开始，最后再装沙子。石头装进去后，沙子就沉积在石头的周围，最后，所有东西都装进瓶子里了。老师说：“如果我们先从小的东西开始，把小东西装进去之后，大的石头就放不进去了。生活也是如此，如果你的生活先被不重要的事挤满了，那你就无法再装进更大、更重要的事了。”'],\n",
       "  ['这几年公司发展得很不错，每年春节前都会发给工人两个月的奖金，但是今年公司却没挣到多少钱。经理很担心工人们会伤心、失望。这天，他突然想起小时候去买糖：别的服务员都是先抓一大把，拿去称，再一颗一颗减少；只有一个服务员，每次都抓不够重量，然后一颗一颗往上加。虽然拿到的糖是一样的，但人们都喜欢后者。经理想到了办法。过了两天，传来一个消息——今年公司发展不好，有些人可能得离开公司。工人们听了之后都开始担心，以为要离开的是自己。后来经理宣布了一个消息：大家都是一家人，虽然公司有困难，但不能丢掉任何人，只是没有奖金了。这个消息使所有的人都放下了心：奖金不重要，有工作就好。春节快到了，工人们都做了过个穷年的打算。这时经理通知开会，工人们又担心：“会有什么变化吗？”谁知参加会议的人回来兴奋地喊道：“有！有！还是有奖金的！一个月的！”工人们听了，发出一片热烈的欢呼声。'],\n",
       "  ['这几年公司发展得很不错，每年春节前都会发给工人两个月的奖金，但是今年公司却没挣到多少钱。经理很担心工人们会伤心、失望。这天，他突然想起小时候去买糖：别的服务员都是先抓一大把，拿去称，再一颗一颗减少；只有一个服务员，每次都抓不够重量，然后一颗一颗往上加。虽然拿到的糖是一样的，但人们都喜欢后者。经理想到了办法。过了两天，传来一个消息——今年公司发展不好，有些人可能得离开公司。工人们听了之后都开始担心，以为要离开的是自己。后来经理宣布了一个消息：大家都是一家人，虽然公司有困难，但不能丢掉任何人，只是没有奖金了。这个消息使所有的人都放下了心：奖金不重要，有工作就好。春节快到了，工人们都做了过个穷年的打算。这时经理通知开会，工人们又担心：“会有什么变化吗？”谁知参加会议的人回来兴奋地喊道：“有！有！还是有奖金的！一个月的！”工人们听了，发出一片热烈的欢呼声。'],\n",
       "  ['这几年公司发展得很不错，每年春节前都会发给工人两个月的奖金，但是今年公司却没挣到多少钱。经理很担心工人们会伤心、失望。这天，他突然想起小时候去买糖：别的服务员都是先抓一大把，拿去称，再一颗一颗减少；只有一个服务员，每次都抓不够重量，然后一颗一颗往上加。虽然拿到的糖是一样的，但人们都喜欢后者。经理想到了办法。过了两天，传来一个消息——今年公司发展不好，有些人可能得离开公司。工人们听了之后都开始担心，以为要离开的是自己。后来经理宣布了一个消息：大家都是一家人，虽然公司有困难，但不能丢掉任何人，只是没有奖金了。这个消息使所有的人都放下了心：奖金不重要，有工作就好。春节快到了，工人们都做了过个穷年的打算。这时经理通知开会，工人们又担心：“会有什么变化吗？”谁知参加会议的人回来兴奋地喊道：“有！有！还是有奖金的！一个月的！”工人们听了，发出一片热烈的欢呼声。'],\n",
       "  ['这几年公司发展得很不错，每年春节前都会发给工人两个月的奖金，但是今年公司却没挣到多少钱。经理很担心工人们会伤心、失望。这天，他突然想起小时候去买糖：别的服务员都是先抓一大把，拿去称，再一颗一颗减少；只有一个服务员，每次都抓不够重量，然后一颗一颗往上加。虽然拿到的糖是一样的，但人们都喜欢后者。经理想到了办法。过了两天，传来一个消息——今年公司发展不好，有些人可能得离开公司。工人们听了之后都开始担心，以为要离开的是自己。后来经理宣布了一个消息：大家都是一家人，虽然公司有困难，但不能丢掉任何人，只是没有奖金了。这个消息使所有的人都放下了心：奖金不重要，有工作就好。春节快到了，工人们都做了过个穷年的打算。这时经理通知开会，工人们又担心：“会有什么变化吗？”谁知参加会议的人回来兴奋地喊道：“有！有！还是有奖金的！一个月的！”工人们听了，发出一片热烈的欢呼声。'],\n",
       "  ['阿凡提是个很聪明的人，也很热心。很多穷人遇到困难都来找他。有一天，一个穷人来到阿凡提的家说：“亲爱的阿凡提，刚才我在有钱人巴依家的饭馆儿门口站了一会儿，他就一定要让我给他饭钱，因为我闻到了他饭馆儿里饭菜的香味。可是你知道我没有钱，他说要去我家拿东西，怎么办呢？”阿凡提对他说：“别着急，我陪你一起去趟巴依家吧。”到了巴依家，阿凡提对巴依说：“这个人是我的朋友，他没有钱，他欠你的饭菜钱我替他还，好吗？”他一边说，一边给巴依看一个小口袋，然后他摇了一下这个口袋，口袋“哗啦哗啦”地响了几下。他问巴依：“这是什么在响啊？”巴依以为阿凡提要给他口袋里的钱，连忙说：“是钱，是钱在响。”“那你听到了吗？”阿凡提又问。“听到了，听到了，快给我吧！”巴依有点儿着急了。“好了，巴依，我的朋友闻了一下你饭菜的香味，你也听了一下我的钱的响声。现在我们的账已经算清楚了。”说完，阿凡提就跟那个穷人一起走了。'],\n",
       "  ['阿凡提是个很聪明的人，也很热心。很多穷人遇到困难都来找他。有一天，一个穷人来到阿凡提的家说：“亲爱的阿凡提，刚才我在有钱人巴依家的饭馆儿门口站了一会儿，他就一定要让我给他饭钱，因为我闻到了他饭馆儿里饭菜的香味。可是你知道我没有钱，他说要去我家拿东西，怎么办呢？”阿凡提对他说：“别着急，我陪你一起去趟巴依家吧。”到了巴依家，阿凡提对巴依说：“这个人是我的朋友，他没有钱，他欠你的饭菜钱我替他还，好吗？”他一边说，一边给巴依看一个小口袋，然后他摇了一下这个口袋，口袋“哗啦哗啦”地响了几下。他问巴依：“这是什么在响啊？”巴依以为阿凡提要给他口袋里的钱，连忙说：“是钱，是钱在响。”“那你听到了吗？”阿凡提又问。“听到了，听到了，快给我吧！”巴依有点儿着急了。“好了，巴依，我的朋友闻了一下你饭菜的香味，你也听了一下我的钱的响声。现在我们的账已经算清楚了。”说完，阿凡提就跟那个穷人一起走了。'],\n",
       "  ['阿凡提是个很聪明的人，也很热心。很多穷人遇到困难都来找他。有一天，一个穷人来到阿凡提的家说：“亲爱的阿凡提，刚才我在有钱人巴依家的饭馆儿门口站了一会儿，他就一定要让我给他饭钱，因为我闻到了他饭馆儿里饭菜的香味。可是你知道我没有钱，他说要去我家拿东西，怎么办呢？”阿凡提对他说：“别着急，我陪你一起去趟巴依家吧。”到了巴依家，阿凡提对巴依说：“这个人是我的朋友，他没有钱，他欠你的饭菜钱我替他还，好吗？”他一边说，一边给巴依看一个小口袋，然后他摇了一下这个口袋，口袋“哗啦哗啦”地响了几下。他问巴依：“这是什么在响啊？”巴依以为阿凡提要给他口袋里的钱，连忙说：“是钱，是钱在响。”“那你听到了吗？”阿凡提又问。“听到了，听到了，快给我吧！”巴依有点儿着急了。“好了，巴依，我的朋友闻了一下你饭菜的香味，你也听了一下我的钱的响声。现在我们的账已经算清楚了。”说完，阿凡提就跟那个穷人一起走了。']],\n",
       " 'question': ['那个任务，学生刚开始完成得怎么样？',\n",
       "  '正确的装法是，先装？',\n",
       "  '上文主要告诉我们，生活中应该？',\n",
       "  '今年公司怎么样？',\n",
       "  '根据经理小时候买糖的情况，可以知道？',\n",
       "  '今年公司的工人',\n",
       "  '关于经理的办法，正确的是？',\n",
       "  '那个穷人为什么来找阿凡提？',\n",
       "  '巴依为什么向那个穷人要钱？',\n",
       "  '阿凡提陪那个穷人去做什么？'],\n",
       " 'choice': [['都没完成', '都装进去了', '完成得很好', '有一组没做完'],\n",
       "  ['小东西', '大东西', '轻的东西', '软的东西'],\n",
       "  ['多思考', '先做小事', '先做重要的事', '多听别人的建议'],\n",
       "  ['发展得不错', '挣的钱不多', '要给工人发糖', '要发两个月的奖金'],\n",
       "  ['服务员给的重量不够', '服务员一块儿一块儿地卖', '服务员卖糖的方式都一样', '不同的卖糖方法影响人的心情'],\n",
       "  ['有人要离开', '得不到奖金', '都参加了会议', '得到了一个月的奖金'],\n",
       "  ['让工人都很难过', '增加了公司的收入', '使工人得到了安慰', '使一部分人丢了工作'],\n",
       "  ['想找他借钱', '想请阿凡提吃饭', '想请阿凡提去他家', '想让阿凡提帮忙想办法'],\n",
       "  ['穷人把巴依的东西拿走了', '穷人在巴依的饭馆儿吃饭了', '穷人闻了巴依饭馆儿菜的香味', '穷人听到了巴依口袋里钱的响声'],\n",
       "  ['去向巴依要钱', '去给巴依饭钱', '去巴依的饭馆儿吃饭', '帮他解决和巴依的问题']],\n",
       " 'answer': ['', '', '', '', '', '', '', '', '', '']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3[\"test\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "    num_rows: 1625\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3.pop(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 11869\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 3816\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='../hfl/chinese-macbert-base', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../hfl/chinese-macbert-base\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(examples):\n",
    "    # examples, dict, keys: [\"context\", \"quesiton\", \"choice\", \"answer\"]\n",
    "    # examples, 1000\n",
    "    context = []\n",
    "    question_choice = []\n",
    "    labels = []\n",
    "    for idx in range(len(examples[\"context\"])):\n",
    "        ctx = \"\\n\".join(examples[\"context\"][idx])\n",
    "        question = examples[\"question\"][idx]\n",
    "        choices = examples[\"choice\"][idx]\n",
    "        for choice in choices:\n",
    "            context.append(ctx)\n",
    "            question_choice.append(question + \" \" + choice)\n",
    "        if len(choices) < 4:\n",
    "            for _ in range(4 - len(choices)):\n",
    "                context.append(ctx)\n",
    "                question_choice.append(question + \" \" + \"不知道\")\n",
    "        labels.append(choices.index(examples[\"answer\"][idx]))\n",
    "    tokenized_examples = tokenizer(context, question_choice, truncation=\"only_first\", max_length=256, padding=\"max_length\")     # input_ids: 4000 * 256, \n",
    "    tokenized_examples = {k: [v[i: i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}     # 1000 * 4 *256\n",
    "    tokenized_examples[\"labels\"] = labels\n",
    "    return tokenized_examples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54f67b9fe6f4261858d3292b82d8a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'choice', 'answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = c3[\"train\"].select(range(10)).map(process_function, batched=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(res[\"input_ids\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685df12d56d4428ca9156e237630c40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd48ad40491c4dcfaa301b643f1e0579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 11869\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3816\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_c3 = c3.map(process_function, batched=True)\n",
    "tokenized_c3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at ../hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(\"../hfl/chinese-macbert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5 创建评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "accuracy = evaluate.load(\"seqeval_metric.py\")\n",
    "\n",
    "def compute_metric(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6 配置TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\llm\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7 Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\柒\\AppData\\Local\\Temp\\ipykernel_18580\\2804359672.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "d:\\miniconda3\\envs\\llm\\lib\\site-packages\\accelerate\\accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_c3[\"train\"],\n",
    "    eval_dataset=tokenized_c3[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step8 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb77794926d04b85a585fb69c4cdb154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9489, 'grad_norm': 17.385498046875, 'learning_rate': 1.955974842767296e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9206, 'grad_norm': 17.104001998901367, 'learning_rate': 1.9110512129380053e-05, 'epoch': 0.13}\n",
      "{'loss': 0.8008, 'grad_norm': 9.345995903015137, 'learning_rate': 1.8661275831087154e-05, 'epoch': 0.2}\n",
      "{'loss': 0.7644, 'grad_norm': 12.675070762634277, 'learning_rate': 1.8212039532794252e-05, 'epoch': 0.27}\n",
      "{'loss': 0.7174, 'grad_norm': 18.228158950805664, 'learning_rate': 1.776280323450135e-05, 'epoch': 0.34}\n",
      "{'loss': 0.7236, 'grad_norm': 17.025001525878906, 'learning_rate': 1.7313566936208447e-05, 'epoch': 0.4}\n",
      "{'loss': 0.6953, 'grad_norm': 18.01833724975586, 'learning_rate': 1.6864330637915545e-05, 'epoch': 0.47}\n",
      "{'loss': 0.6568, 'grad_norm': 14.94517993927002, 'learning_rate': 1.6415094339622643e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6694, 'grad_norm': 26.861228942871094, 'learning_rate': 1.596585804132974e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6877, 'grad_norm': inf, 'learning_rate': 1.5525606469002698e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6588, 'grad_norm': 20.322036743164062, 'learning_rate': 1.5076370170709795e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\llm\\lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\llm\\lib\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\llm\\lib\\site-packages\\transformers\\trainer.py:3612\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3612\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3613\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\llm\\lib\\site-packages\\accelerate\\accelerator.py:1962\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1961\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1962\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1964\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\llm\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\llm\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\llm\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step9 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MultipleChoicePipeline:\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.mdoel = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.device\n",
    "\n",
    "    def preprecess(self, context, question, choices):\n",
    "        ctx, qcs = [], []\n",
    "        for choice in choices:\n",
    "            ctx.append(context)\n",
    "            qcs.append(question + \" \" + choice)\n",
    "        return tokenizer(ctx, qcs, truncation=\"only_first\", max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}\n",
    "        return self.model(**inputs).logits\n",
    "\n",
    "    def postprocess(self, logits, choices):\n",
    "        prediction = torch.argmax(logits, dim=-1).cpu().item()\n",
    "        return prediction\n",
    "\n",
    "    def __call__(self, context, question, choices):\n",
    "        inputs = self.preprecess(context, question, choices)\n",
    "        logits = self.predict(inputs)\n",
    "        result = self.postprocess(logits, choices)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MultipleChoicePipeline(model, tokenizer)\n",
    "\n",
    "context = [\"女: 小明你在哪里上班\", \"男: 我在北京上班\"]\n",
    "question = \"小明在哪里上班\"\n",
    "choices = [\"北京\", \"上海\", \"深圳\"]\n",
    "\n",
    "pipe = (context, question, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
